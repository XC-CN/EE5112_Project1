# 模型文件目录

将从 Hugging Face 仓库 `meta-llama/Llama-3.1-8B-Instruct` 下载的 GGUF 量化模型放在此文件夹内，例如：

```
Llama-3.1-8B-Instruct-Q4_K_M.gguf
```

下载方式见同级目录下的 `README.md` 或运行 `download_model.py` 脚本。