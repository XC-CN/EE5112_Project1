llama-cpp-python[cuda]>=0.2.0
numpy>=1.24.0
tqdm>=4.64.0
requests>=2.28.0
