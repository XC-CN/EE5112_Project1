{
    "model_config": {
        "model_path": "models/Llama-3.2-3B-Instruct-Q4_K_M.gguf",
        "n_gpu_layers": 35,
        "n_ctx": 4096,
        "n_threads": 8,
        "verbose": false,
        "seed": -1
    },
    "generation_config": {
        "temperature": 0.7,
        "top_p": 0.9,
        "top_k": 40,
        "repeat_penalty": 1.1,
        "max_tokens": 512
    },
    "dialogue_config": {
        "max_history": 10,
        "system_prompt": "You are a helpful AI assistant. Provide clear, concise, and helpful responses.",
        "save_conversations": true,
        "conversation_dir": "conversations",
        "streaming": true
    },
    "hardware_config": {
        "gpu_enabled": true,
        "max_gpu_layers": 35,
        "memory_fraction": 0.9
    }
}
